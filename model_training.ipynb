{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mykhalevychv/emotion_recognition/blob/main/model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hGXzoeBGq1Q"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten,AveragePooling2D\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras import Sequential\n",
        "from keras.utils import plot_model\n",
        "import cv2\n",
        "import os\n",
        "import warnings\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf2h0cqasvw2",
        "outputId": "7e210a56-eb93-4e70-995e-5f028ae116ac"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "  \n",
        "from google.colab import drive\n",
        "import sys\n",
        "from pathlib import Path\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "base = Path('/content/drive/My Drive/project/')\n",
        "sys.path.append(str(base))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfDj9p-HLCdb"
      },
      "source": [
        "%cd /content/drive/MyDrive/project/\n",
        "train_dir = '/content/drive/MyDrive/project/fer2013/train/'\n",
        "test_dir = '/content/drive/MyDrive/project/fer2013/test/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAftMc17M0fs"
      },
      "source": [
        "print('training pictures\\n')\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(14,22))\n",
        "i = 1\n",
        "for expression in os.listdir(train_dir):\n",
        "    img = load_img((train_dir + expression +'/'+ os.listdir(train_dir + expression)[3]))\n",
        "    plt.subplot(1,7,i)\n",
        "    plt.imshow(img)\n",
        "    plt.title(expression)\n",
        "    plt.axis('off')\n",
        "    i += 1\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I16EnXPAxuFs",
        "outputId": "ff3849bb-d483-4a49-b06b-84745e07ca3b"
      },
      "source": [
        "row, col = 48, 48\n",
        "classes = 7\n",
        "\n",
        "def count_exp(path, set_):\n",
        "    dict_ = {}\n",
        "    for expression in os.listdir(path):\n",
        "        dir_ = path + expression\n",
        "        dict_[expression] = len(os.listdir(dir_))\n",
        "    df = pd.DataFrame(dict_, index=[set_])\n",
        "    return df\n",
        "train_count = count_exp(train_dir, 'train')\n",
        "test_count = count_exp(test_dir, 'test')\n",
        "print(train_count)\n",
        "print(test_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       angry  disgust  fear  happy  neutral   sad  surprise\n",
            "train   3995      436  5108   7215     4965  4830      3171\n",
            "      angry  disgust  fear  happy  neutral   sad  surprise\n",
            "test    958      111  1024   1774     1233  1247       831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M6wzj8nJilx",
        "outputId": "4d96755e-d586-4c18-f5f4-3df9823c45f0"
      },
      "source": [
        "train_datagen = ImageDataGenerator(#rotation_range = 180,\n",
        "                                         width_shift_range = 0.1,\n",
        "                                         height_shift_range = 0.1,\n",
        "                                         #brightness_range = [0.1,1.1],\n",
        "                                         horizontal_flip = True,\n",
        "                                         #vertical_flip = True,\n",
        "                                         rescale = 1./255,\n",
        "                                         zoom_range = 0.2,\n",
        "                                         validation_split = 0.2\n",
        "                                        )\n",
        "validation_datagen =ImageDataGenerator(rescale = 1./255,\n",
        "                                             validation_split = 0.2)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(directory = train_dir,\n",
        "                                                               target_size = (48,48),\n",
        "                                                               color_mode = \"grayscale\",\n",
        "                                                               class_mode = \"categorical\",\n",
        "                                                               batch_size = 64,\n",
        "                                                               #shuffle = False,\n",
        "                                                               subset = \"training\"\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(directory = test_dir,\n",
        "                                                             target_size = (48,48),\n",
        "                                                             color_mode = \"grayscale\",\n",
        "                                                             class_mode = \"categorical\",\n",
        "                                                             batch_size = 64,\n",
        "                                                             #shuffle = True,\n",
        "                                                             subset = \"validation\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 29720 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTBZviJlGlwT"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_set = test_datagen.flow_from_directory(test_dir,\n",
        "                                                batch_size=64,\n",
        "                                                target_size=(48, 48),\n",
        "                                                shuffle=True,\n",
        "                                                color_mode='grayscale',\n",
        "                                                class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaCEF0PRMrHn"
      },
      "source": [
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, patience=6, mode='auto')\n",
        "checkpointer = ModelCheckpoint('./weights.h5', monitor='val_loss', verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyHBPrrOMrJt"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax\n",
        "from tensorflow.keras import layers\n",
        "loss='categorical_crossentropy'\n",
        "from tensorflow.keras import regularizers\n",
        "optimizer = 'rmsprop'          \n",
        "metrics = ['accuracy']\n",
        "\n",
        "def cnn_model(conv_activation='relu', dropout_rate=0.25, optimizer='rmsprop',learning_rate=0.001,n = 512, epochs=10):\n",
        "    \n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (3, 3), input_shape = (48,48,1),activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, (3, 3),activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    if dropout_rate != 0:\n",
        "        model.add(Dropout(rate=dropout_rate))      \n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, (3, 3),activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
        "    if dropout_rate != 0:\n",
        "        model.add(Dropout(rate=dropout_rate))  \n",
        "\n",
        "    model.add(Conv2D(256, (3, 3),activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, (3, 3),activation = 'relu'))\n",
        "    model.add(BatchNormalization())       \n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    if dropout_rate != 0:\n",
        "        model.add(Dropout(rate=dropout_rate)) \n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(n))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(rate=0.25))\n",
        "    model.add(Dense(7))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    if optimizer == 'rmsprop':\n",
        "        opt = RMSprop(lr=learning_rate)\n",
        "    if optimizer == 'adam':\n",
        "        opt = Adam(lr=learning_rate)\n",
        "    if optimizer == 'sgd':\n",
        "        opt = SGD(lr=learning_rate)\n",
        "    if optimizer == 'adamax':\n",
        "        opt = Adamax(lr=learning_rate)\n",
        "    model.compile(optimizer=opt,  loss=loss,  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 64\n",
        " \n",
        "cnn_1 = cnn_model()\n",
        "\n",
        "#cnn_model.compile(optimizer=opt,  loss=loss,  metrics=['accuracy'])\n",
        "\n",
        "cnn_1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy3WwswTNZEK"
      },
      "source": [
        "plot_model(cnn_1, to_file='model.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DBqnKBVNeVK"
      },
      "source": [
        "hist_model_cnn = cnn_1.fit(train_generator, steps_per_epoch =22968//64, epochs = 60,validation_data = validation_generator,validation_steps = 1432//64,  callbacks=[lr_reducer, checkpointer, early_stopper])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFS4GkwcNlpp"
      },
      "source": [
        "cnn_1.save('./model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aITTdNykNrhX"
      },
      "source": [
        "y_pred = k.predict(train_generator)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "class_labels = validation_generator.class_indices\n",
        "class_labels = {v:k for k,v in class_labels.items()}\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "cm_train = confusion_matrix(train_generator.classes, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(cm_train)\n",
        "print('Classification Report')\n",
        "target_names = list(class_labels.values())\n",
        "print(classification_report(train_generator.classes, y_pred, target_names=target_names))\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(cm_train, interpolation='nearest')\n",
        "plt.colorbar()\n",
        "tick_mark = np.arange(len(target_names))\n",
        "_ = plt.xticks(tick_mark, target_names, rotation=90)\n",
        "_ = plt.yticks(tick_mark, target_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfx6lDhzNsSJ"
      },
      "source": [
        "y_pred = k.predict(test_set)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "class_labels = test_set.class_indices\n",
        "class_labels = {v:k for k,v in class_labels.items()}\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "cm_train = confusion_matrix(test_set.classes, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(cm_train)\n",
        "print('Classification Report')\n",
        "target_names = list(class_labels.values())\n",
        "print(classification_report(test_set.classes, y_pred, target_names=target_names))\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(cm_train, interpolation='nearest')\n",
        "plt.colorbar()\n",
        "tick_mark = np.arange(len(target_names))\n",
        "_ = plt.xticks(tick_mark, target_names, rotation=90)\n",
        "_ = plt.yticks(tick_mark, target_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTc7BxuuNz8N"
      },
      "source": [
        "print(\"rmsprop, lr = 0,001, 60 epochs\")\n",
        "#  \"Accuracy\"\n",
        "plt.plot(hist_model_cnn.history['accuracy'])\n",
        "plt.plot(hist_model_cnn.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "# \"Loss\"\n",
        "plt.plot(hist_model_cnn.history['loss'])\n",
        "plt.plot(hist_model_cnn.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpFMurjqN3MR"
      },
      "source": [
        "train_loss, train_acc = k.evaluate(train_generator)\n",
        "test_loss, test_acc   = k.evaluate(test_set)\n",
        "print(\"final train accuracy = {:.2f} , validation accuracy = {:.2f}\".format(train_acc*100, test_acc*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsqCrRFtN9hN"
      },
      "source": [
        "(X_train, Y_train) = train_generator.next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl2Hv3mgN-Fo"
      },
      "source": [
        "from datetime import datetime\n",
        "from time import time, sleep\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# optimize model \n",
        "start = time()\n",
        "n_epochs=10\n",
        "# define function to display the results of the grid search\n",
        "def display_cv_results(search_results):\n",
        "    print('Best score = {:.4f} using {}'.format(search_results.best_score_, search_results.best_params_))\n",
        "    means = search_results.cv_results_['mean_test_score']\n",
        "    stds = search_results.cv_results_['std_test_score']\n",
        "    params = search_results.cv_results_['params']\n",
        "    for mean, stdev, param in zip(means, stds, params):\n",
        "        print('mean test accuracy +/- std = {:.4f} +/- {:.4f} with: {}'.format(mean, stdev, param))  \n",
        "# create model\n",
        "model = KerasClassifier(build_fn=cnn_model, verbose=1)\n",
        "# define parameters and values for grid search \n",
        "param_grid = {\n",
        "    'dropout_rate' : [0.25, 0.5],\n",
        "    'conv_activation': ['relu','tahn','sigmoid'],    \n",
        "    'n':[256,512],\n",
        "    #'epochs': [n_epochs],\n",
        "    'optimizer': ['rmsprop','adam','sgd',],\n",
        "    'learning_rate': [0.01, 0.001, 0.0001]\n",
        "}\n",
        "n_cv = 5\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=n_cv)\n",
        "grid_result = grid.fit(X_train, Y_train)\n",
        "\n",
        "# summarize results\n",
        "print('time for grid search = {:.0f} sec'.format(time()-start))\n",
        "display_cv_results(grid_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKrGaObSMrM4"
      },
      "source": [
        "#visualize filters from first layer\n",
        "from matplotlib import pyplot\n",
        "# retrieve weights from the second hidden layer\n",
        "filters, biases = cnn_1.layers[1].get_weights()\n",
        "# normalize filter values to 0-1 so we can visualize them\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "# plot first few filters\n",
        "#pyplot.figure(figsize=(1,1))\n",
        "pyplot.figure(figsize=(10, 8), dpi=100)\n",
        "n_filters, ix = 6, 1\n",
        "for i in range(n_filters):\n",
        "\t# get the filter\n",
        "\tf = filters[:, :, :, i]\n",
        "\t# plot each channel separately figure(figsize=(8, 6), dpi=80)\n",
        "\tfor j in range(3):\n",
        "\t\t# specify subplot and turn of axis\n",
        "\t\tax = pyplot.subplot(n_filters, 3, ix)\n",
        "\t\tax.set_xticks([])\n",
        "\t\tax.set_yticks([])\n",
        "\t\t# plot filter channel in grayscale\n",
        "\t\tpyplot.imshow(f[:, :, j], cmap='gray')\n",
        "\t\tix += 1\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxcacfHaMrQe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFPXwYqOGqOs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}